# Search & RAG

Describes how DocDuck performs similarity search and constructs answers.

## Steps (/query)
1. Embed question text
2. Retrieve top-K chunks by cosine distance (`embedding <=> query_vector`)
3. Concatenate chunk texts (ordered by ascending distance)
4. Prompt model to synthesize answer
5. Return answer + mapped sources (filename + snippet + distance)

## /docsearch Variation
- Retrieves more chunks (capped) then groups by `doc_id`
- Selects top documents by best (lowest) chunk distance
- Returns representative snippet from each doc

## Distance Metric
- Cosine distance via pgvector ops: `embedding <=> $query`
- Lower distance â‡’ higher similarity

## Filters
- Optional `providerType` and `providerName` narrow search

## Ranking Quality Levers
| Lever | Effect |
|-------|-------|
| Chunk Size | Too large: diluted relevance; too small: fragmented context |
| Overlap | Prevents context boundary loss |
| Top-K | Higher recall vs prompt cost tradeoff |

## Potential Enhancements
| Idea | Description |
|------|-------------|
| Reranking | Cross-encoder reorder after initial vector search |
| Hybrid | Combine BM25 + vector union/intersection |
| Metadata Filters | Restrict by path, date, tag |
| Feedback Loop | Reinforce chunk weighting based on user acceptance |

## Failure Modes
| Mode | Symptom | Mitigation |
|------|---------|------------|
| Sparse Index | Generic answers | Ensure enough documents, adjust chunk size |
| Overlap Too Low | Missing context | Increase `CHUNK_OVERLAP` |
| Overlap Too High | Cost spike | Reduce overlap when stable |

## Next
- Data schema: [Schema](../database/schema.md)
